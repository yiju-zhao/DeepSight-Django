# Xinference Configuration for Audio Transcription
# URL where Xinference server is running
XINFERENCE_URL=http://localhost:9997

# Model UID for the Whisper model deployed in Xinference
# This should match the UID used when deploying the model to Xinference
XINFERENCE_WHISPER_MODEL_UID=whisper-large-v3-turbo

# Xinference Configuration for Report Agent LLM
# Base URL for Xinference API (OpenAI-compatible endpoint)
XINFERENCE_API_BASE=http://localhost:9997/v1

# API key (can be a dummy value for local Xinference)
XINFERENCE_API_KEY=dummy

# RagFlow Configuration
# API key for RagFlow service
RAGFLOW_API_KEY=your-ragflow-api-key

# Base URL for RagFlow service
RAGFLOW_BASE_URL=https://demo.ragflow.io:9380

# Default chunk method for document processing
RAGFLOW_CHUNK_METHOD=naive

# Default embedding model for vector storage
RAGFLOW_EMBEDDING_MODEL=Qwen3-Embedding-0.6B@Xinference

# Chat model for RagFlow agents
RAGFLOW_CHAT_MODEL=deepseek-chat@DeepSeek

# Django Configuration
SECRET_KEY=your-secret-key-here
HOST_IP=localhost
BACKEND_PORT=8000
FRONTEND_PORT=5173

# Report Agent LLM Configuration
# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_API_TYPE=openai
OPENAI_API_BASE=
OPENAI_API_VERSION=
AZURE_API_KEY=

# Google Configuration
GOOGLE_API_KEY=your-google-api-key-here

# Search API Configuration (for report agent retrieval)
TAVILY_API_KEY=your-tavily-api-key-here
BRAVE_API_KEY=
SERPER_API_KEY=
YOU_API_KEY=
BING_API_KEY=
SEARXNG_URL=
SEARXNG_API_KEY=

# MiniMax TTS Configuration
MINIMAX_GROUP_ID=
MINIMAX_API_KEY=

# Document Processing
MINERU_BASE_URL=